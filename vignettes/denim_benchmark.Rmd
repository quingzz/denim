---
title: "denim benchmark"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{denim benchmark}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
python:
  python_path: /opt/anaconda3/envs/bnn/bin/python
bibliography: references.bib
---

To assess denim's performance, we benchmark it against other available packages, listed in the table below.

+-----------+------------+--------------------------------------------------------------------+
| Package   | Model time | Note                                                               |
+===========+============+====================================================================+
| uSEIR     | discrete   | 2 implementations for uSEIR that will be tested                    |
|           |            |                                                                    |
|           |            | -   Implementation in Python                                       |
|           |            |                                                                    |
|           |            | -   Implementation in Cython                                       |
+-----------+------------+--------------------------------------------------------------------+
| deSolve   | continuous | 3 ways to define model for deSolve that will be tested             |
|           |            |                                                                    |
|           |            | -   Model in R                                                     |
|           |            |                                                                    |
|           |            | -   Model in C                                                     |
|           |            |                                                                    |
|           |            | -   Model in Fortran                                               |
+-----------+------------+--------------------------------------------------------------------+
| IONISE    | continuous |                                                                    |
+-----------+------------+--------------------------------------------------------------------+
| diffeqr   | continuous | 2 ways to run model in diffeqr will be tested                      |
|           |            |                                                                    |
|           |            | -   Define model in R                                              |
|           |            |                                                                    |
|           |            | -   Define model in Julia                                          |
+-----------+------------+--------------------------------------------------------------------+
| odin      | discrete   | A manual implementation of denim's algorithm, using odin is tested |
+-----------+------------+--------------------------------------------------------------------+
| denim     | discrete   | Two methods for defining distributions are tested:                 |
|           |            |                                                                    |
|           |            | -   Built-in parametric functions                                  |
|           |            |                                                                    |
|           |            | -   Histograms using the `nonparametric()` function                |
+-----------+------------+--------------------------------------------------------------------+

The benchmarking process was conducted on a Macbook Pro with M2 Pro chip, 16 GBs of RAM and 10 cores (6 performance and 4 efficiency).Â 

```{r echo=FALSE, warning=FALSE, message=FALSE}
library(tidyverse)
# loading cached run time if available
cached_runtime <- if (file.exists("../supplements/cached_runtime.rds")) {
  readRDS("../supplements/cached_runtime.rds")
} else {
  NULL
}
```

## Benchmark settings

All approaches will simulate the following SEIR model, with the same simulation duration of 180

```{r echo=FALSE}
DiagrammeR::grViz("digraph {
  graph [layout = dot, rankdir = LR]
  
  node [shape = rectangle]
  
  S -> E [label = 'beta * S * (I / N)']
  E -> I [label = 'd_gamma(1/4,2)']
  I -> R [label = 'd_gamma(1/3,2)']
  }",
  width = 700, height = "100%")
```

`beta` can also be computed as $beta = R_0/tr$ where $R_0$ is the basic reproduction number and $tr$ is the infectious period.

Each approach will be run 50 times

```{r benchmark settings}
total_runs <- 50L # number of runs
sim_duration <- 180 # duration of simulation
```

## 1. uSEIR

Simulate model using uSEIR approach [@Hernndez2021].

Source code: <https://github.com/jjgomezcadenas/useirn/blob/master/nb/uSEIR.ipynb>

<details>

<summary>load useir implementation in pure Python</summary>

```{r}
library(reticulate)
# use_python("/opt/anaconda3/envs/bnn/bin/python", required = TRUE)
use_condaenv(condaenv='bnn', required = TRUE)
matplotlib <- import("matplotlib")
matplotlib$use("Agg", force = TRUE)
py_run_file("../supplements/useir_python.py")
```

</details>

### 1.1. Python implementation

<details>

<summary>Code for running uSEIR in pure Python</summary>

```{python}
#| output: false
import time
import concurrent.futures
import pickle
import os
from statistics import mean

python_runs = []

def get_python_runtime(n):
  start = time.time()
  df = solve_uSeir(ti_shape     = 2,
                     ti_scale     = 4,
                     tr_shape     = 2,
                     tr_scale     = 3,
                     R0           = 3.5)
  end = time.time()
  return end - start
  
# load cached result if available instead of rerun due to long run time
cached_python_runs = "../supplements/cached_runs/python_runs.pkl"
if os.path.exists(cached_python_runs):
  # If the file exists, load the Python list from the file
  with open(cached_python_runs, 'rb') as f:
    python_runs = pickle.load(f)
else:
  print("no cache found")
  # multithread instead for quicker result
  with concurrent.futures.ProcessPoolExecutor(max_workers=8) as executor:
    python_runs = list(executor.map(get_python_runtime, range(r.total_runs)))
  # Save to cache
  with open(cached_python_runs, 'wb') as f:
      pickle.dump(python_runs, f)
      
# plot_useir((df,), ('G',), T = 'uSEIR', figsize=(14,8))
# print(f'python solve_seir call: dr = {end-start}')
```

</details>

Run time for uSEIR approach, Python implementation (in seconds)

```{r echo = FALSE}
python_runs <- if(is.null(cached_runtime)){
  py$python_runs
}else{
  cached_runtime$python_runs
}
python_runs
```

Median run time for uSEIR approach, Python implementation: `r median(py$python_runs)` seconds

### 1.2. Cython implementation

<details>

<summary>Code for running uSEIR in Cython (C backend)</summary>

```{python}
#| output: false
# import precompiled cython module
import sys
sys.path.insert(0, "../supplements")
import useir
import time
import pyarrow as pa

cython_runs = []

# --- Get runtime ----
for i in range(r.total_runs):
  start = time.time()
  df = useir.csolve_uSeir(dist = "gamma",
                    ti_shape     = 2,
                     ti_scale     = 4,
                     tr_shape     = 2,
                     tr_scale     = 3,
                     R0           = 3.5
  )
  end = time.time()

  cython_runs = cython_runs + [end - start]

# ---- Get output for uSEIR -----
df = useir.csolve_uSeir(dist = "gamma",
                    ti_shape     = 2,
                     ti_scale     = 4,
                     tr_shape     = 2,
                     tr_scale     = 3,
                     R0           = 3.5,
                     pde_sampling = ""
  )
  
# convert to pyarrow table for easy conversion to R data.frames
to_r_df = pa.Table.from_pandas(df)
```

</details>

Run time for uSEIR approach, Cython implementation (in seconds)

```{r echo=FALSE}
cython_runs <- if(is.null(cached_runtime)){
  py$cython_runs
}else{
  cached_runtime$cython_runs
}
cython_runs
```

Median run time for uSEIR approach, Cython implementation: `r median(cython_runs)` seconds

## 2. deSolve

Simulate model using deSolve package [@soetaert2008]

### 2.1. Model in R

```{=html}
<details>
  <summary>Code for running SEIR in <code>deSolve</code></summary>
```
```{r}
library(deSolve)
parameters <- c(gamma_rate_I = 1/4, shape_I=2,
                gamma_rate_R = 1/3, shape_R = 2,
                R0 = 3.5, N = 1e6) 
initialValues <- c(S = 999999, E1 = 1,
                   E2 = 0, E = 0, I1=0, 
                   I2=0, I=0, R=0
                   )

# --- Transition def for deSolve
transition_func <- function(t, state, param){
  with(as.list( c(state, param) ), {
      tr = shape_R*(1/gamma_rate_R)
      
      dS = - (R0/tr) * S * I/N
      # apply linear chain trick
      dE1 = (R0/tr) * S * I/N - gamma_rate_I*E1
      dE2 = gamma_rate_I*E1 - gamma_rate_I*E2
      dE = dE1 + dE2
      dI1 = gamma_rate_I*E2 - gamma_rate_R*I1
      dI2 = gamma_rate_R*I1 - gamma_rate_R*I2
      dI =  dI1 + dI2

      dR = gamma_rate_R*I2
      list(c(dS, dE1, dE2, dE, dI1, dI2, dI, dR))
  })
}

times <- seq(0, sim_duration, 1)

# ------ Compute run time ------
desolve_runs <- if(is.null(cached_runtime)){
  bench::mark(
    ode(y = initialValues, times = times, parms = parameters, func = transition_func),
    iterations = total_runs
  )$time[[1]]
}else{
  cached_runtime$desolve_runs
}

ode_mod <- ode(y = initialValues, times = times, parms = parameters, func = transition_func)
ode_mod <- as.data.frame(ode_mod)
```

</details>

Run time for `deSolve` implementation

```{r echo = FALSE}
desolve_runs
```

Median run time for deSolve, with model defined in R: `r median(desolve_runs)` seconds

### 2.2. Model in C

```{=html}
<details>
  <summary>Code for running model defined in C</summary>
```
```{r}
# compile model
# system("R CMD SHLIB supplements/desolve_mod/benchmark_mod.c")

# compiled file on Windows will have .dll extension instead of .so
dyn.load("../supplements/desolve_mod/benchmark_mod.so")

initialValues <- c(S = 999999, E1 = 1,
                   E2 = 0, E = 0, I1=0, 
                   I2=0, I=0, R=0
                   )

parameters <- c(R0 = 3.5, scale_I = 4, shape_I=2,
                scale_R = 3, shape_R = 2, N = 1e6) 

desolve_c_runs <- if(is.null(cached_runtime)){
  bench::mark(
    # run model defined in C
    ode(initialValues, times, func = "derivs", parms = parameters,
    dllname = "benchmark_mod", initfunc = "initmod"),
    iterations = total_runs
  )$time[[1]]
}else{
  cached_runtime$desolve_c_runs
}

dyn.unload("../supplements/desolve_mod/benchmark_mod.so")
```

</details>

Run time for `deSolve` with model defined in C

```{r}
desolve_c_runs
```

Median run time for deSolve, with model defined in C: `r median(desolve_c_runs)` seconds

### 2.3. Model in Fortran

```{=html}
<details>
  <summary>Code for running model defined in C</summary>
```
```{r}
# compile model in fortran
# system("R CMD SHLIB supplements/desolve_mod/benchmark_mod_fortran.f")

dyn.load("../supplements/desolve_mod/benchmark_mod_fortran.so")

initialValues <- c(S = 999999, E1 = 1,
                   E2 = 0, E = 0, I1=0, 
                   I2=0, I=0, R=0
                   )

parameters <- c(R0 = 3.5, scale_I = 4, shape_I=2,
                scale_R = 3, shape_R = 2, N = 1e6) 

desolve_fortran_runs <- if(is.null(cached_runtime)){
  bench::mark(
    # run model defined in Fortran
    ode(initialValues, times, func = "derivs", parms = parameters,
    dllname = "benchmark_mod_fortran", initfunc = "initmod"),
    iterations = total_runs
  )$time[[1]]
}else{
  cached_runtime$desolve_fortran_runs
}

dyn.unload("../supplements/desolve_mod/benchmark_mod_fortran.so")
```

</details>

```{r}
desolve_fortran_runs
```

Median run time for deSolve, with model defined in Fortran: `r median(desolve_fortran_runs)` seconds

## 3. IONISE

Simulate model using IONISE approach [@hong2024].

Source code: <https://github.com/Mathbiomed/IONISE>

<details>

<summary>Code for running SEIR using `IONISE`</summary>

```{r}
# load code for IONISE
source("../supplements/ionise_mod/IONISE.R")

# ------ Set up -------
ionise_time <- seq(0, sim_duration, 1)
ionise_params <- c(
  3.5/6, # beta 
  2, 4, # rate and shape E -> I transition
  2, 3 # rate and shape I -> R transition
)
inonise_init <-  c(S_init = 999999, E_init = 1, I_init = 0, R_init = 0)

# ------ Compute run time ------
ionise_runs <- if(is.null(cached_runtime)){
  bench::mark(
    # run model defined using IONISE
    mean_trajectory_SEIR_dist_input(
      timespan = ionise_time,
      theta = ionise_params,
      y_init = inonise_init,
      dist_type = "gamma"
    ),
    iterations = total_runs
  )$time[[1]]
}else{
  cached_runtime$ionise_runs
}

# ----- Format output ------ 
ionise_out <- mean_trajectory_SEIR_dist_input(
  timespan = ionise_time,
  theta = ionise_params,
  y_init = inonise_init,
  dist_type = "gamma"
) %>% as.data.frame() %>% 
  rename(
    S = St,
    E = Et,
    I = It,
    R = Rt
  ) %>% 
  mutate(
    time = ionise_time
  )
```

</details>

```{r}
ionise_runs
```

Median run time for IONISE: `r median(ionise_runs)` seconds

## 4. diffeqr

Simulate model using diffeqr package [@rackauckas]

### 4.1. Model in R

<details>

<summary>Code for running SEIR using `diffeqr`</summary>

Setup Julia for `diffeqr`

```{r}
# load library
library(diffeqr)

# uncomment to check Julia version
# JuliaCall::julia_command("VERSION")
# uncomment to resolve error: type RFunction has no field r
# JuliaCall::julia_command('using Pkg; Pkg.add(PackageSpec(name = "ModelingToolkit", version = "8.76.0"))')
# uncomment to check installed packages version
# JuliaCall::julia_command('using Pkg; Pkg.installed()')
```

Set up SEIR model

```{r}
# --- Transition def for diffeqr ------ 
diffeqr_transition <- function(u, p, t){
  # p - gamma_rate_I, shape_I, gamma_rate_R, shape_R, R0, N
  # u - S, E1, E2, E, I1, I2, I, R
  tr = p[4]*(1/p[3])
  
  dS = - (p[5]/tr) * u[1] * u[7]/p[6]
  # apply linear chain trick
  dE1 = (p[5]/tr) * u[1] * u[7]/p[6] - p[1]*u[2]
  dE2 = p[1]*u[2] - p[1]*u[3]
  dE = dE1 + dE2
  dI1 = p[1]*u[3] - p[3]*u[5]
  dI2 = p[3]*u[5] - p[3]*u[6]
  dI =  dI1 + dI2

  dR = p[3]*u[6]
  
  return(c(dS, dE1, dE2, dE, dI1, dI2, dI, dR))
}

diffeqr_time <- c(0, sim_duration)

# ---- Parameter setup -----
parameters <- c(gamma_rate_I = 1/4, shape_I=2,
                gamma_rate_R = 1/3, shape_R = 2,
                R0 = 3.5, N = 1e6) 
initialValues <- c(S = 999999, E1 = 1,
                   E2 = 0, E = 0, I1=0, 
                   I2=0, I=0, R=0
                   )

# set up diffeqr solverr
setup <- diffeq_setup()
# we can use initialValues and parameters set up for deSolve
diffeqr_mod <- setup$ODEProblem(diffeqr_transition, 
                                initialValues,
                                diffeqr_time, 
                                parameters)


# ------ Compute run time ------
diffeqr_base_runs <- if(is.null(cached_runtime)){
  bench::mark(
    setup$solve(diffeqr_mod),
    iterations = total_runs
  )$time[[1]]
}else{
  cached_runtime$diffeqr_base_runs
}

# ----- Format output ------ 
sol <- setup$solve(diffeqr_mod)
out_mat <- sapply(sol$u,identity)
# convert to data.frame
diffeqr_out <- as.data.frame(t(out_mat))
# add names
names(diffeqr_out) <- names(initialValues)
# add time column
diffeqr_out <- diffeqr_out %>% mutate(
    time = identity(sol$t)
  )
```

</details>

```{r}
diffeqr_base_runs
```

Median run time for `diffeqr` with base solver: `r median(diffeqr_base_runs)` seconds

### 4.2. Define model in Julia

<details>

<summary>Code to set up model in Julia using `diffeqr`</summary>

We can tell `diffeqr` to define model in Julia, so we can utilize Julia JIT compiler which can improve the runtime.

```{r}
# define model in Julia instead
optimized_mod <- diffeqr::jitoptimize_ode(setup, diffeqr_mod)

diffeqr_optimized_runs <- if(is.null(cached_runtime)){
  bench::mark(
    solve(optimized_mod, setup$Tsit5()),
    iterations = total_runs
  )$time[[1]]
}else{
  cached_runtime$diffeqr_optimized_runs
}
```

</details>

```{r}
diffeqr_optimized_runs
```

Median run time for IONISE: `r median(diffeqr_optimized_runs)` seconds

## 5. odin {#sec-odin}

We also implement uSEIR model with denim's algorithm using `odin` package [@fitzjohn2024] for comparison

<details>

<summary>Code for running SEIR in `odin`</summary>

```{r message = FALSE, output = FALSE, warning=TRUE}
# ---- Install packages -----
# install.packages(
#   "odin2",
#   repos = c("https://mrc-ide.r-universe.dev", "https://cloud.r-project.org"))
# install.packages(
#   "dust2",
#   repos = c("https://mrc-ide.r-universe.dev", "https://cloud.r-project.org"))
library(odin2)

odin_mod <- odin2::odin(
  {
    # ----- Define algo to update compartments here ---------
    update(S) <- S - dt * (R0/tr) * S * sum(I)/N

    # --- E compartment ------
    update(E[1]) <- dt * (R0/tr) * S * sum(I)/N
    # starting from 2: to simulate individuals staying in E for another timestep
    update(E[2:e_maxtime]) <- E[i-1]*(1-e_transprob[i-1])
    
    # compute total population from E -> I
    dim(E_to_I) <- e_maxtime
    E_to_I[1:e_maxtime] <- e_transprob[i]*E[i]
    sum_E_to_I <- sum(E_to_I)
    
    # --- I compartment ------
    update(I[1]) <- sum_E_to_I
    update(I[2:i_maxtime]) <- I[i-1]*(1-i_transprob[i-1])
    
    # compute total population from I -> R
    dim(I_to_R) <- i_maxtime
    I_to_R[1:i_maxtime] <- i_transprob[i]*I[i]
    sum_I_to_R <- sum(I_to_R)

    # --- R compartment ------
    update(R) <- R + sum_I_to_R
    
    # initialize population from input
    initial(S) <- S_init
    initial(E[]) <- E_init[i]
    dim(E) <- e_maxtime
    initial(I[]) <- I_init[i]
    dim(I) <- i_maxtime
    initial(R) <- R_init

    # ----- Inputs -------
    R0 <- parameter()
    tr <- parameter()
    
    # transition prob of E
    e_transprob<- parameter()
    e_maxtime <- parameter()
    dim(e_transprob) <- e_maxtime
    
    # transition prob of I
    i_transprob <- parameter()
    i_maxtime <- parameter()
    dim(i_transprob) <- i_maxtime
    
    
    # initial populations
    S_init <- user()
    E_init <- user()
    dim(E_init) <- e_maxtime
    I_init <- user()
    dim(I_init) <- i_maxtime
    R_init <- user()
    N <- parameter(1000)
  }
)

compute_transprob <- function(dist_func,..., timestep=0.05, error_tolerance=0.001){
  maxtime <- timestep
  prev_prob <- 0
  transprob <- numeric()
  cumulative_dist <- numeric()
  prob_dist <- numeric()
  
  while(TRUE){
     # get current cumulative prob and check whether it is sufficiently close to 1
     temp_prob <-  ifelse(
       dist_func(maxtime, ...) < (1 - error_tolerance), 
       dist_func(maxtime, ...), 
       1);
     cumulative_dist <- c(cumulative_dist, temp_prob)
     
     # get f(t)
     curr_prob <- temp_prob - prev_prob
     prob_dist <- c(prob_dist, curr_prob)
     
     # compute transprob
     curr_transprob <- curr_prob/(1-prev_prob)
     transprob <- c(transprob, curr_transprob)
     
     prev_prob <- temp_prob
     maxtime <- maxtime + timestep
     
     if(temp_prob == 1){
       break
     }
  }
  
  data.frame(
    prob_dist = prob_dist,
    cumulative_dist = cumulative_dist,
    transprob = transprob
  )
}
```

Run model for bench mark. Note that the process of computing the transition probability is also included as part of the benchmark for a fair comparison with denim.

```{r}
timeStep <- 0.01
errorTolerance <- 0.001

run_useir_odin <- function(){
  # ---- Compute transprob ----- 
  e_transprob <- compute_transprob(pgamma, rate=1/4, shape=2, 
                                   timestep = timeStep, error_tolerance = errorTolerance)$transprob
  i_transprob <- compute_transprob(pgamma, rate=1/3, shape=2, 
                                   timestep = timeStep, error_tolerance = errorTolerance)$transprob
  
  # ---- Run model and plot ----- 
  # initialize params
  odin_pars <- list(
    R0 = 3.5, 
    tr = 3*2, # compute mean recovery time, for gamma it's scale*shape
    N = 1e6,
    e_transprob = e_transprob,
    e_maxtime = length(e_transprob),
    i_transprob = i_transprob,
    i_maxtime = length(i_transprob),
    S_init = 999999, 
    E_init = array( c(1, rep(0, length(e_transprob) - 1) ) ),
    I_init = array( rep(0, length(i_transprob)) ),
    R_init = 0
  )
  
  # run model
  t_seq <- seq(0, sim_duration, 0.25)
  odin_seir <- dust2::dust_system_create(odin_mod, odin_pars, dt = timeStep)
  dust2::dust_system_set_state_initial(odin_seir)
  out <- dust2::dust_system_simulate(odin_seir, t_seq)
  out <- dust2::dust_unpack_state(odin_seir, out)
  
  data.frame(
    t = t_seq,
    S = out$S,
    E = colSums(out$E),
    I = colSums(out$I),
    R = out$R
  )
}

# ---- Get runtimes ----
odin_runs <- if(is.null(cached_runtime)){
  bench::mark({
      run_useir_odin()
    },
    iterations = total_runs
  )$time[[1]]
}else{
  cached_runtime$odin_runs
}

odin_out <- run_useir_odin()
```

</details>

```{r}
odin_runs
```

Median run time for odin: `r median(odin_runs)` seconds

## 6. denim

### 6.1. Parametric

<details>

<summary>Code for running SEIR in `denim`</summary>

```{r}
timeStep <- 0.01
errorTolerance <- 0.001

library(denim)

denim_model <- denim_dsl({
  S -> E = (R0/tr) * S * (I/N) 
  E -> I = d_gamma(rate = 1/4, shape = 2)
  I -> R = d_gamma(rate = 1/3, shape = 2)
})

initialValues <- c(S = 999999, E = 1, I= 0, R= 0)
parameters <- c(R0 = 3.5, 
                tr = 3*2, # compute mean recovery time, for gamma it's scale*shape
                N = 1e6)

# ---- Get runtimes ----
denim_runs <- if(is.null(cached_runtime)){
  bench::mark(
    sim(
      transitions = denim_model,
      initialValues = initialValues,
      parameters = parameters,
      simulationDuration = sim_duration,
      timeStep = timeStep,
      errorTolerance = errorTolerance
    ), 
    iterations = total_runs
  )$time[[1]]
}else{
  cached_runtime$denim_runs
}


# ---- Get output ----
denim_out <- sim(transitions = denim_model, 
                     initialValues = initialValues,
                     parameters = parameters,
                     simulationDuration = sim_duration, timeStep = timeStep)
plot(denim_out)
```

</details>

Run time for `denim` implementation

```{r}
denim_runs
```

Median run time for denim: `r median(denim_runs)` seconds

### 6.2. Nonparametric

We can also define the SEIR model in denim using function `nonparametric()` where the dwell-time distribution will be pre-computed using the helper function from Section \@ref(sec-odin)

<details>

<summary>Code for running SEIR in `denim`</summary>

```{r}
timeStep <- 0.01
errorTolerance <- 0.001

denim_nonparametric_model <- denim_dsl({
  S -> E = (R0/tr) * S * (I/N) 
  E -> I = nonparametric(ei_dist) #ei_dist is considered a model parameter
  I -> R = nonparametric(ir_dist) #ir_dist is also a model parameter
})

initialValues2 <- c(S = 999999, E = 1, I= 0, R= 0)

ei_dist <- compute_transprob(pgamma, rate = 1/4, shape = 2, 
                             timestep = timeStep, error_tolerance = errorTolerance)$prob_dist
ir_dist <- compute_transprob(pgamma, rate = 1/3, shape = 2, 
                             timestep = timeStep, error_tolerance = errorTolerance)$prob_dist

parameters2 <- list(R0 = 3.5, 
                tr = 3*2, # compute mean recovery time, for gamma it's scale*shape
                N = 1e6,
                ei_dist = ei_dist, 
                ir_dist = ir_dist)

# ---- Get runtimes ----
denim_nonparametric_runs <- if(is.null(cached_runtime)){
  bench::mark(
    sim(transitions = denim_nonparametric_model,
                       initialValues = initialValues2,
                       parameters = parameters2,
                       simulationDuration = sim_duration, timeStep = timeStep),
    iterations = total_runs
  )$time[[1]]
}else{
  cached_runtime$denim_nonparametric_runs
}

# ---- Get output ----
denim_nonparametric_out <- sim(transitions = denim_nonparametric_model, 
                     initialValues = initialValues2,
                     parameters = parameters2,
                     simulationDuration = sim_duration, timeStep = timeStep)
```

</details>

Run time for `denim`, using `nonparametric()` with pre-computed distribution

```{r}
denim_nonparametric_runs
```

Median run time for denim using `nonparametric()` with pre-computed distribution: `r median(denim_nonparametric_runs)` seconds.

This longer run time compared to parametric approach is due to the overhead of interfacing large vectors (`ei_dist` and `ir_dist` in this example) between R and C++. For this reason, it is recommended to only use `nonparametric()` when the observed distribution cannot be adequately represented by one of the available parametric transitions.

## 7. Visualize output

The plot below compare output of discrete time frameworks (`odin`, `denim`, `uSEIR`) with that of a continuous time solver `deSolve`.

```{r echo=FALSE, warning=FALSE, message=FALSE}
library(arrow)
library(reticulate)
df <- as.data.frame(py$to_r_df)

# ---- Preprocess data ---
# compute prop to compare with uSEIR
rescaled_denim <- denim_out
rescaled_denim[, c("S","E", "I", "R")] <- rescaled_denim[, c("S","E", "I", "R")]/1e6

# compute prop for odin output
rescaled_odin <- odin_out
rescaled_odin[, c("S","E", "I", "R")] <- rescaled_odin[, c("S","E", "I", "R")]/1e6

# compute prop for IONISE output
rescaled_ionise <- ionise_out
rescaled_ionise[, c("S","E", "I", "R")] <- rescaled_ionise[, c("S","E", "I", "R")]/1e6

# compute prop for diffeqr output
rescaled_diffeqr <- diffeqr_out
rescaled_diffeqr[, c("S","E", "I", "R")] <- rescaled_diffeqr[, c("S","E", "I", "R")]/1e6

# compute prop for deSolve output as well
rescaled_desolve <- ode_mod
rescaled_desolve[, c("S","E", "I", "R")] <- rescaled_desolve[, c("S","E", "I", "R")]/1e6


# ---- Helper function for plotting ---
plot_output_compare <- function(df, baseline = rescaled_desolve, time_col = "Time", approach = "denim"){
  comps <- c("S", "E", "I", "R")
  
  reshape_output <- function(data, label, 
                           values_to = "pop",
                           names_to = "compartment",
                           comps = c("S", "E", "I", "R"),  
                           time = "time") {
    data %>% 
      select(all_of(c(time, comps))) %>%
      pivot_longer(
        cols = comps,
        values_to = "pop",
        names_to = "compartment"
      ) %>% 
      mutate(
        approach = label
      ) %>% 
      rename(time = {{time}})
  }
  
  df <- reshape_output(df, approach, comps = comps, time = time_col)
  baseline <- reshape_output(baseline, "deSolve", comps = comps, time = "time")
  
  bind_rows(df, baseline) %>% 
    ggplot() +
      geom_line(
        aes(x = time, y = pop, color = approach, linetype = approach),
        show.legend = c(color = TRUE, linetype = FALSE))+
      facet_wrap(~ compartment, scales = "free") +
      scale_color_manual(
        labels = c("deSolve", approach),
        values = c("black", "cornflowerblue")
      ) + 
      theme_bw() +
      labs(
        x = "Time",
        y = "Prop",
        title = paste0("Compare output between deSolve and ", approach)
      )
}

# ---- Plot and save plot -----
# plot_output_compare(rescaled_denim)
# ggsave("../manuscript_plots/denim_desolve.png", width = 8, height = 5, dpi = 300)

# plot_output_compare(rescaled_odin, time_col = "t", approach = "odin")
# ggsave("../manuscript_plots/odin_desolve.png", width = 8, height = 5, dpi = 300)

# plot_output_compare(df, time_col = "t",  approach = "uSEIR")
# ggsave("../manuscript_plots/useir_desolve.png", width = 8, height = 5, dpi = 300)

# plot_output_compare(rescaled_ionise, time_col = "time",  approach = "IONISE")

# plot_output_compare(rescaled_diffeqr, time_col = "time",  approach = "diffeqr")
```

```{r echo=FALSE, warning=FALSE}
# plot pairwise comparison
plot_pairwise <- function(df, baseline = rescaled_desolve, time_col = "Time", approach = "denim"){
  comps <- c("S", "E", "I", "R")
  
  # create a long-data for plotting
  df <- df %>%
    select(all_of(c(time_col, comps))) %>%
    pivot_longer(
      cols = comps,
      values_to = "output",
      names_to = "comps"
    )
  
  baseline <- baseline %>%
    select(all_of(c("time", comps))) %>%
    pivot_longer(
      cols = comps,
      values_to = "baseline",
      names_to = "comps"
    )
  
  baseline %>% 
    left_join(
      df, 
      by = join_by(time == {{time_col}}, comps == comps)
    ) %>% 
    arrange(time) %>% 
    ggplot() +
      geom_point(
        aes(x = baseline, y = output),
        color = "cornflowerblue",
        shape = 20,
        show.legend = c(color = TRUE, linetype = FALSE)
      ) +
      # draw the target line
      geom_line(
        aes(x = baseline, y = baseline),
        color = "red",
        linetype = "dashed",
        show.legend = c(color = TRUE, linetype = FALSE)
      ) +
      facet_wrap(~ comps, scales = "free") +
      theme_bw() +
      labs(
        x = "deSolve (baseline)",
        y = approach,
        title = paste0("Compare output between deSolve and ", approach),
        caption = glue::glue("*Data points closer to the dashed line indicate better alignment between the baseline's and {approach}'s outputs.")
      )
}

plot_pairwise(df, time_col = "t",  approach = "uSEIR")
# ggsave("../manuscript_plots/useir_desolve2.png", width = 8, height = 5, dpi = 300)
plot_pairwise(rescaled_denim, time_col = "Time",  approach = "denim")
# ggsave("../manuscript_plots/denim_desolve2.png", width = 8, height = 5, dpi = 300)
plot_pairwise(rescaled_odin, time_col = "t",  approach = "odin")
# ggsave("../manuscript_plots/odin_desolve2.png", width = 8, height = 5, dpi = 300)
plot_pairwise(
  rescaled_diffeqr %>% mutate(
    join_time = round(time)
    ), 
  time_col = "join_time",  approach = "diffeqr")
plot_pairwise(rescaled_ionise, time_col = "time",  approach = "IONISE")
```

## 8. Compare run time

```{r echo=FALSE}
# first cache run time if not already available
cached_runtime <- if(is.null(cached_runtime)){
  list(
    python_runs = python_runs,
    cython_runs = cython_runs,
    desolve_runs = desolve_runs,
    desolve_c_runs = desolve_c_runs,
    desolve_fortran_runs = desolve_fortran_runs,
    ionise_runs = ionise_runs,
    diffeqr_base_runs = diffeqr_base_runs,
    diffeqr_optimized_runs = diffeqr_optimized_runs,
    odin_runs = odin_runs,
    denim_runs = denim_runs,
    denim_nonparametric_runs = denim_nonparametric_runs
  )
} else{
  cached_runtime
}

if(!file.exists("../supplements/cached_runtime.rds")){
  saveRDS(cached_runtime, "../supplements/cached_runtime.rds")
}
```

The following plot shows run time for 50 runs (with horizontal line showing median run time) of each approach.

```{r echo=FALSE}
benchmark_runs <- list(
    "deSolve (R)"       = cached_runtime$desolve_runs,
    "deSolve (C)"       = cached_runtime$desolve_c_runs,
    "deSolve (Fortran)" = cached_runtime$desolve_fortran_runs,
    "IONISE" = cached_runtime$ionise,
    "diffeqr (R)" = cached_runtime$diffeqr_base_runs,
    "diffeqr (Julia)" = cached_runtime$diffeqr_optimized_runs,
    "uSEIR (Python)"    = cached_runtime$python_runs,
    "uSEIR (Cython)"    = cached_runtime$cython_runs,
    "odin"              = cached_runtime$odin_runs,
    "denim"             = cached_runtime$denim_runs,
    "denim (nonparametric)" = cached_runtime$denim_nonparametric_runs
  )

discrete_time <- c(
  "odin", "denim", "denim (nonparametric)", "uSEIR (Python)", "uSEIR (Cython)"
)

apply_log <- TRUE

# Convert list to long format df
plot_df <- imap_dfr(benchmark_runs, \(run_times, method) {
  tibble(
    method = method,
    run = 1:total_runs,
    time = as.numeric(run_times),
    model_time = if_else(method %in% discrete_time, "discrete", "continuous")
  )
})

# Apply log transform if specified
# if (apply_log) {
#   plot_df$time <- log(plot_df$time)
# }

# Compute medians for each method
medians <- plot_df %>%
  group_by(method, model_time) %>%
  mutate(median_time = median(time)) %>% 
  ungroup()

# Create the plot
runtime_plot <- ggplot(plot_df, aes(x = run, y = time, color = method, shape = model_time)) +
  geom_point(alpha = 0.7,
             show.legend = c(color = FALSE, shape = TRUE)) +
  geom_segment(
    data = medians,
    aes(x = -2, xend = total_runs + 2, y = median_time, color = method),
    linetype = "dashed",
    linewidth = 0.3,
    show.legend = FALSE
  ) +
  geom_text(data = medians, 
            aes(x = total_runs + 3, y = median_time, label = method, color = method),
            hjust = 0, size = 2.5, show.legend = FALSE) +
  labs(
    title = paste0("Run time for ", total_runs, " runs"),
    x = "Run",
    y = "Run time (seconds)",
    color = "Approach",
    shape = "Model time"
  ) +
  scale_x_continuous(
    limits = c(-2,  total_runs + 15),
    breaks = seq(0, 50, 10)
  ) +
  theme_bw() +
  theme(legend.position = "right")

# Apply log scale to y-axis if requested
if (apply_log) {
  runtime_plot <- runtime_plot + scale_y_log10() +
    labs(y = "Run time (seconds)")
}

runtime_plot
# save plots
# ggsave("../manuscript_plots/benchmark_all_log_new.png", width = 8, height = 5, dpi = 300)
```

## 9. Impact of timeStep in denim

### 9.1. Run time scaling

It is worth noting that runtime for denim is also dependent on duration of time step (`timeStep` parameter for `sim`).

The following plot demonstrates how run time changes as value for timeStep changes, using the same model for benchmarking. The values for timeStep being evaluated are `[0.01, 0.02, 0.05, 0.1, 0.25, 0.5, 1]`.

```{r echo=FALSE}
timeStepDurations <- c(0.01, 0.02, 0.05, 0.1, 0.25, 0.5, 1)
runtime_scaling <- sapply(timeStepDurations, 
     \(x){
       time <- bench::mark(
         sim(transitions = denim_model,
                   initialValues = initialValues,
                   parameters = parameters,
                   simulationDuration = sim_duration, timeStep = x)
       )
       
       time$median
     }
   )
```

```{r echo=FALSE, warning=FALSE}
plot(x = timeStepDurations, y = runtime_scaling, col = "cornflowerblue",
     xlab = "Time step duration",
     ylab = "Median run time (in seconds)")
lines(x = timeStepDurations, y = runtime_scaling, col = "cornflowerblue",
     xlab = "Time step duration",
     ylab = "Median run time (in seconds)")
abline(v = timeStep, col = "red", lty = 2, lwd = 2)  
abline(v = 1, col = "blueviolet", lty = 2, lwd = 2)  
text(x = timeStep, y = max(unlist(runtime_scaling)), labels = "timeStep for benchmarking", col = "red", pos = 4)
text(x = 1, y = max(unlist(runtime_scaling)), labels = "default timeStep", col = "blueviolet", pos = 2)
```

### 9.2. Impact on accuracy

Aside from run time, duration of time step also impacts the accuracy of `denim`'s output.

The following plots demonstrates how precision is compromised as we increase the duration for time step (with output from `deSolve` used as baseline). The values for timeStep being evaluated are `[0.01, 0.1, 0.5, 1]`.

```{r echo = FALSE}
timeStepDurations <- c(0.01, 0.1, 0.5, 1)

# --- generate output at each time step -----
out <- map_dfr(timeStepDurations, \(x){
  data <- sim(
     transitions = denim_model,
     initialValues = initialValues,
     parameters = parameters,
     simulationDuration = sim_duration,
     timeStep = x
   ) %>% 
    mutate(
      S = S/1e6, E = E/1e6, I = I/1e6, R = R/1e6
    )
  
  data %>% 
    filter(Time %% 1 == 0) %>% 
    mutate(
      approach = paste0("denim dt=", x)
    )
})

# --- Manually set color palettes -----
set_linetype <- setNames(
  rep("solid", length(timeStepDurations)),
  unique(out$approach)
)
set_color <- setNames(
  colorspace::qualitative_hcl(length(timeStepDurations)),
  unique(out$approach)
)

# --- Merge with deSolve for plotting -----
bind_rows(
  rescaled_desolve %>% 
    select(time, S, E, I, R) %>% 
    rename(Time = time) %>% 
    mutate(
      approach = "deSolve (baseline)"
    ),
    out
  ) %>% 
  pivot_longer(cols = c("S", "E", "I", "R"), values_to = "prop", names_to = "comp") %>% 
  # ----- Plot ------
  ggplot() +
    geom_line(
      aes(x = Time, y = prop, color = approach, linetype = approach)
    ) +
    scale_color_manual(
      values = c("deSolve (baseline)" = "black", set_color)
    ) +
    scale_linetype_manual(
      values = c("deSolve (baseline)" = "dashed", set_linetype)
    ) + 
    theme_bw() +
    theme(legend.title = element_blank()) +
    facet_wrap(~ comp, scales = "free") +
    labs(
      title = "Denim output at different timeStep",
      x = "Time",
      y = "Prop"
    )

# ---- Uncomment to save plot -----
# ggsave(
#   glue::glue("../manuscript_plots/denim_dt.png"),
#   width = 8, height = 5, dpi = 300)
```

```{r echo=FALSE}
# ---- reshape output to create pair-wise comparison plot ---
reshaped_baseline <- rescaled_desolve %>% 
  select(time, S, E, I, R) %>% 
  pivot_longer(
    cols = c("S", "E", "I", "R"),
    names_to = "comp",
    values_to = "baseline"
  )
reshaped_out <- out %>% 
  pivot_longer(
    cols = c("S", "E", "I", "R"),
    names_to = "comp",
    values_to = "output"
  )

reshaped_baseline %>% 
  left_join(
    reshaped_out,
    by = join_by(time == Time, comp == comp)
  ) %>% 
  # pivot_longer(cols = c("S", "E", "I", "R"), values_to = "prop", names_to = "comp") %>% 
  ggplot() +
    geom_point(
      aes(x = baseline, y = output, color = approach),
      shape = 20
    ) +
    geom_line(
      aes(x = baseline, y = baseline),
      color = "black", linetype = "dashed"
    ) + 
    theme_bw() +
    theme(legend.title = element_blank()) +
    facet_wrap(~ comp, scales = "free") +
    labs(
      title = "Denim output at different timeStep",
      x = "deSolve (baseline)",
      y = "denim",
      caption = "*Data points closer to the dashed line indicate better alignment between the baseline and denim outputs."
    )

# ggsave(
#   glue::glue("../manuscript_plots/denim_dt_pairwise.png"),
#   width = 8, height = 5, dpi = 300)
```
